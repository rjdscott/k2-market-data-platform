name: PR Validation (Fast)

on:
  pull_request:
    branches: [main, develop, enhance-binance]
  push:
    branches: [main, develop, enhance-binance]

# Cancel previous runs on new push
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.13"

permissions:
  contents: read
  security-events: write

jobs:
  quality-checks:
    name: Quality (Lint + Type + Format)
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "latest"

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --frozen

      - name: Run Ruff (lint)
        run: uv run ruff check src/ tests/ --exclude=tests/unit/test_consumer_legacy.py

      - name: Run Black (format check)
        run: uv run black --check src/ tests/ --exclude=tests/unit/test_consumer_legacy.py

      - name: Run isort (import order)
        run: uv run isort --check-only src/ tests/

      - name: Run mypy (type check)
        run: uv run mypy src/

  unit-tests:
    name: Unit Tests (Parallel)
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --frozen

      - name: Run unit tests
        run: |
          uv run pytest tests/unit/ \
            -v \
            -n 4 \
            --maxfail=5 \
            --tb=short \
            --junitxml=pytest-unit-results.xml

      # Performance tests temporarily disabled
      # - name: Run performance tests (sequential to prevent OOM)
      #   run: |
      #     uv run pytest tests/performance/ \
      #       -v \
      #       -n 0 \
      #       -m performance \
      #       --tb=short \
      #       --junitxml=pytest-performance-results.xml

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: pytest-*-results.xml
          retention-days: 7

  security-scan:
    name: Security Scan (Trivy)
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  pr-validation-summary:
    name: PR Validation Summary
    runs-on: ubuntu-latest
    needs: [quality-checks, unit-tests, security-scan]
    if: always()

    steps:
      - name: Check job statuses
        run: |
          echo "Quality Checks: ${{ needs.quality-checks.result }}"
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"

          if [ "${{ needs.quality-checks.result }}" != "success" ] || \
             [ "${{ needs.unit-tests.result }}" != "success" ] || \
             [ "${{ needs.security-scan.result }}" != "success" ]; then
            echo "❌ PR Validation FAILED"
            exit 1
          else
            echo "✅ PR Validation PASSED"
          fi
