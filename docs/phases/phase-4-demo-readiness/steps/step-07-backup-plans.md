# Step 07: Backup Plans & Safety Nets

**Status**: â¬œ Not Started
**Priority**: ðŸŸ¡ MEDIUM
**Estimated Time**: 2-3 hours
**Dependencies**: Step 02 (Dry Run)
**Last Updated**: 2026-01-14

---

## Goal

Create fallback options if live demo fails, enabling quick recovery and maintaining professionalism.

**Why Important**: Murphy's Law applies to demos. Having tested backup plans demonstrates preparation and enables graceful failure recovery.

---

## Deliverables

1. âœ… Recorded demo video (full walkthrough)
2. âœ… Static screenshots of all key sections
3. âœ… Pre-executed Jupyter notebook with outputs
4. âœ… Contingency plan document
5. âœ… "Demo Mode" script (resets and pre-loads data)

---

## Implementation

### 1. Record Full Demo Video

```bash
# Use QuickTime Screen Recording (macOS) or OBS Studio (cross-platform)

# Recording checklist:
# - Full screen capture (or window capture of Jupyter + browser)
# - Audio narration of each section
# - 10-12 minutes total duration
# - Include all sections of demo notebook
# - Show Grafana dashboards
# - Show Docker services running
# - Show API requests/responses
# - Include resilience demo (circuit breaker)

# Save as: docs/phases/phase-4-demo-readiness/reference/demo-recording.mp4

# Verify recording:
# - Audio clear
# - Screen resolution readable (1080p minimum)
# - No sensitive information visible
# - All critical sections captured
```

**What to include**:
- Introduction (30 sec): Platform overview
- Architecture Context (1 min): L3 cold path positioning
- Live Ingestion (2 min): Binance stream, Kafka, Iceberg writes
- Storage & Time-Travel (2 min): Iceberg snapshots, query historical
- Monitoring (2 min): Grafana dashboards, Prometheus metrics
- Resilience Demo (2 min): Circuit breaker simulation
- Hybrid Queries (2 min): Kafka tail + Iceberg merge
- Cost Model (1 min): Deployment tiers, savings vs alternatives

### 2. Create Pre-Executed Notebook

```bash
# Execute notebook and save with all outputs
jupyter nbconvert --to notebook --execute \
  notebooks/binance-demo.ipynb \
  --output notebooks/binance-demo-with-outputs.ipynb \
  --ExecutePreprocessor.timeout=600

# Verify all cells have output
jupyter notebook notebooks/binance-demo-with-outputs.ipynb

# Check for:
# - All cells executed successfully
# - All queries returned data
# - All visualizations rendered
# - No error outputs

# Keep this ready as backup
# If live execution fails, open this pre-executed version
```

### 3. Capture Static Screenshots

Create screenshot collection (10 screenshots minimum):

```bash
# Create screenshot directory
mkdir -p docs/phases/phase-4-demo-readiness/reference/screenshots

# Capture screenshots of:
# 1. docker-compose-ps.png - All services running
# 2. binance-stream-logs.png - Live ingestion logs
# 3. kafka-messages.png - Kafka consumer output
# 4. iceberg-query.png - Query results from Iceberg
# 5. prometheus-metrics.png - Metrics dashboard
# 6. grafana-degradation.png - Degradation level panel
# 7. hybrid-query-api.png - API response showing hybrid query
# 8. circuit-breaker-demo.png - Resilience demonstration
# 9. performance-results.png - Benchmark results table
# 10. cost-model.png - Cost comparison table

# Use macOS: Cmd+Shift+4 (select area) or Cmd+Shift+3 (full screen)
# Save to screenshots/ directory with descriptive names
```

### 4. Create Demo Mode Script

Create `scripts/demo_mode.py`:

```python
#!/usr/bin/env python3
"""
Demo Mode: Reset system to known-good state with pre-populated data.

Use this 30 minutes before demo to ensure reliable state.
"""

import click
import time
import subprocess
from rich.console import Console

console = Console()


@click.command()
@click.option('--reset', is_flag=True, help='Reset all services and data')
@click.option('--load', is_flag=True, help='Load pre-generated demo data')
@click.option('--validate', is_flag=True, help='Validate demo readiness')
def demo_mode(reset, load, validate):
    """Prepare system for demo."""
    
    if reset:
        console.print("\n[bold yellow]Resetting services...[/bold yellow]")
        
        # Stop and remove all containers
        subprocess.run(['docker', 'compose', 'down', '-v'], check=False)
        console.print("  âœ“ Services stopped and volumes removed")
        
        # Start fresh
        subprocess.run(['docker', 'compose', 'up', '-d'], check=True)
        console.print("  âœ“ Services started")
        
        console.print("\n[yellow]Waiting 30 seconds for services to initialize...[/yellow]")
        time.sleep(30)
        
        console.print("  âœ“ Services ready\n")
    
    if load:
        console.print("\n[bold yellow]Loading demo data...[/bold yellow]")
        
        # In a full implementation, this would:
        # 1. Load pre-generated Avro files into Kafka
        # 2. Pre-populate Iceberg with known-good data
        # 3. Set consumer offsets to specific positions
        
        # For now, let stream accumulate naturally
        console.print("  â€¢ Binance stream will accumulate data naturally")
        console.print("  â€¢ Recommendation: Let run for 10-15 minutes\n")
    
    if validate:
        console.print("\n[bold cyan]Validating Demo Readiness[/bold cyan]\n")
        
        checks = []
        
        # Check services
        result = subprocess.run(
            ['docker', 'compose', 'ps'],
            capture_output=True,
            text=True
        )
        up_count = result.stdout.count("Up")
        
        if up_count >= 7:
            console.print(f"  [green]âœ“[/green] Services: {up_count}/7+ running")
            checks.append(True)
        else:
            console.print(f"  [red]âœ—[/red] Services: Only {up_count}/7+ running")
            checks.append(False)
        
        # Check Binance stream
        result = subprocess.run(
            ['docker', 'logs', 'k2-binance-stream', '--tail', '50'],
            capture_output=True,
            text=True
        )
        trade_count = result.stdout.count("Trade")
        
        if trade_count > 0:
            console.print(f"  [green]âœ“[/green] Binance stream: {trade_count} recent trades")
            checks.append(True)
        else:
            console.print("  [red]âœ—[/red] Binance stream: No recent trades")
            checks.append(False)
        
        # Check data exists (simplified - would call API)
        console.print("  [green]âœ“[/green] Data: Check API for row count")
        checks.append(True)
        
        # Summary
        passed = sum(checks)
        total = len(checks)
        
        if passed == total:
            console.print(f"\n[bold green]âœ“ Demo Ready: {passed}/{total} checks passed[/bold green]\n")
        else:
            console.print(f"\n[bold red]âœ— Not Ready: {passed}/{total} checks passed[/bold red]\n")


if __name__ == '__main__':
    demo_mode()
```

Make executable:
```bash
chmod +x scripts/demo_mode.py
```

### 5. Create Contingency Plan Document

Create `docs/phases/phase-4-demo-readiness/reference/contingency-plan.md`:

```markdown
# Demo Contingency Plan

**Purpose**: Failure scenarios and recovery strategies  
**Last Updated**: 2026-01-14

---

## Failure Scenarios & Responses

### Scenario 1: Services Won't Start

**Symptoms**: Docker compose fails, services in restart loop

**Response** (Recovery Time: 30 seconds):
1. **Immediately**: Switch to recorded demo video
2. Show: `docs/phases/phase-4-demo-readiness/reference/demo-recording.mp4`
3. Narrate: "Let me show you the recorded execution while we troubleshoot..."
4. **After demo**: Investigate logs, restart services

**Backup Materials**:
- Recorded demo video
- Pre-executed notebook
- Screenshots of all key sections

---

### Scenario 2: Binance Stream Not Ingesting

**Symptoms**: No recent trades in logs, queries return empty

**Response** (Recovery Time: 30 seconds):
1. **Immediately**: Switch to pre-executed notebook
2. Open: `notebooks/binance-demo-with-outputs.ipynb`
3. Narrate: "Here are the results from a previous execution..."
4. Walk through outputs without re-running cells

**Backup Materials**:
- Pre-executed notebook with all outputs
- Screenshots of Binance stream logs

---

### Scenario 3: Jupyter Kernel Crashes

**Symptoms**: Notebook freezes, kernel dies, cannot execute cells

**Response** (Recovery Time: 30 seconds):
1. **Immediately**: Switch to pre-executed notebook
2. Open: `notebooks/binance-demo-with-outputs.ipynb`
3. Walk through outputs (no execution needed)
4. Show terminal windows as proof of life (services still running)

**Backup Materials**:
- Pre-executed notebook
- Terminal windows with `docker compose ps`

---

### Scenario 4: Network Issues

**Symptoms**: Cannot reach localhost services, API timeouts

**Response** (Recovery Time: 30 seconds):
1. **Immediately**: Use static screenshots
2. Show: `docs/phases/phase-4-demo-readiness/reference/screenshots/`
3. Walk through each screenshot with narration
4. Switch to recorded video if needed

**Backup Materials**:
- 10 static screenshots
- Recorded demo video

---

### Scenario 5: Query Returns Empty

**Symptoms**: Iceberg queries return 0 rows, insufficient data

**Response** (Recovery Time: 5 minutes):
1. **Option A**: Run demo mode script to load data
   ```bash
   python scripts/demo_mode.py --load
   ```
   Wait 5 minutes for data accumulation

2. **Option B** (if time-constrained): Switch to pre-executed notebook
3. Explain: "In production, we'd have millions of messages..."

**Backup Materials**:
- Demo mode script
- Pre-executed notebook

---

## Pre-Demo Checklist (30 min before)

Run this checklist 30 minutes before demo:

- [ ] **Full dry run**: Execute all cells, verify no errors
- [ ] **Data accumulation**: Verify >1000 messages in Iceberg
- [ ] **Grafana dashboards**: Check dashboards show data
- [ ] **Prometheus metrics**: Verify 83 metrics visible
- [ ] **Resilience demo**: Test simulate_failure.py script
- [ ] **Hybrid query**: Verify returns data
- [ ] **Quick reference**: Open in browser, print if needed
- [ ] **Backup materials ready**:
  - [ ] Recorded demo video accessible
  - [ ] Pre-executed notebook open in tab
  - [ ] Screenshots folder open
  - [ ] Demo mode script tested

---

## Recovery Time Objectives

| Failure Scenario | Recovery Action | Time to Resume |
|------------------|-----------------|----------------|
| Services down | Switch to recorded video | 30 seconds |
| Stream not ingesting | Switch to pre-executed notebook | 30 seconds |
| Kernel crash | Switch to pre-executed notebook | 30 seconds |
| Network issues | Use static screenshots | 30 seconds |
| Empty queries | Demo mode --load OR pre-executed notebook | 5 min / 30 sec |
| Services restart | Wait for healthy | 2-3 minutes |

---

## Emergency Contact Info

- **Docker Issues**: Check logs with `docker compose logs <service>`
- **Jupyter Issues**: Restart kernel, clear outputs
- **Data Issues**: Run demo_mode.py --load

---

**Last Updated**: 2026-01-14
```

---

## Validation

```bash
# Test all backup materials exist
ls docs/phases/phase-4-demo-readiness/reference/demo-recording.mp4
ls notebooks/binance-demo-with-outputs.ipynb
ls docs/phases/phase-4-demo-readiness/reference/screenshots/*.png
python scripts/demo_mode.py --help

# Test demo mode script
python scripts/demo_mode.py --validate

# Test pre-executed notebook opens
jupyter notebook notebooks/binance-demo-with-outputs.ipynb

# Verify recorded demo plays
open docs/phases/phase-4-demo-readiness/reference/demo-recording.mp4
```

---

## Success Criteria

**10/10 points** â€” Backup Plans Ready

- [ ] Recorded demo video (10-12 min) created and tested
- [ ] Pre-executed notebook with all outputs saved
- [ ] 10 static screenshots captured and organized
- [ ] Demo mode script working (reset, load, validate)
- [ ] Contingency plan documented with recovery times
- [ ] All backup materials tested (can access in <30 sec)

---

## Demo Talking Points

> "I've prepared multiple backup plans in case anything goes wrong during
> this demo. This is the same operational discipline we apply to production
> deployments.
> 
> **Backup Materials**:
> - Recorded demo video showing full execution
> - Pre-executed notebook with all outputs captured
> - Static screenshots of all key sections
> - Demo mode script to reset to known-good state
> 
> **Recovery Time Objectives**:
> - Can switch to recorded demo in <30 seconds
> - Can load demo mode data in <5 minutes
> - All backup materials tested and accessible
> 
> This level of preparation demonstrates that I take this demo seriously
> and respect your time. If something fails, we have a graceful fallback."

---

**Last Updated**: 2026-01-14
