# Phase 12: Quick Start Guide

**Get Flink Bronze Layer running in 5 minutes**

---

## Prerequisites

```bash
# Ensure core infrastructure is running
docker ps | grep -E "kafka|schema-registry|minio|iceberg-rest"
```

All should show `Up` and `(healthy)` status.

---

## 1. Start Flink Cluster (2 minutes)

```bash
# Start Flink services
docker compose up -d flink-jobmanager flink-taskmanager-1 flink-taskmanager-2

# Wait for health checks
sleep 30

# Verify cluster
curl http://localhost:8082  # Should return HTML
curl -s http://localhost:8082/taskmanagers | jq '.taskmanagers | length'  # Should return 2
```

**Expected output**:
```
k2-flink-jobmanager      Up 1 minute (healthy)
k2-flink-taskmanager-1   Up 1 minute (healthy)
k2-flink-taskmanager-2   Up 1 minute (healthy)
```

‚úÖ **Checkpoint**: Flink Web UI accessible at http://localhost:8082

---

## 2. Start Data Streams (1 minute)

```bash
# Start Binance and Kraken streaming sources
docker compose up -d binance-stream kraken-stream

# Verify streams producing data
docker logs binance-stream | grep "Published"
docker logs kraken-stream | grep "Published"
```

‚úÖ **Checkpoint**: Kafka topics receiving messages

---

## 3. Submit Bronze Jobs (2 minutes)

```bash
# Submit Flink SQL jobs
docker compose up -d flink-bronze-binance-job flink-bronze-kraken-job

# Wait for submission
sleep 60

# Check job logs
docker logs k2-flink-bronze-binance-job | grep -E "INFO|ERROR"
docker logs k2-flink-bronze-kraken-job | grep -E "INFO|ERROR"
```

**Expected output**: All SQL statements succeed with `[INFO] Execute statement succeed.`

‚úÖ **Checkpoint**: Jobs submitted without errors

---

## 4. Verify Jobs Running (PENDING FIX)

**Current Status**: ‚ö†Ô∏è Jobs execute but don't persist

**Issue**: SQL client in embedded mode doesn't keep INSERT jobs running

**Fix Needed** (5 minutes):
```bash
# Edit SQL files
vim config/flink-sql/bronze_binance_ingestion.sql
vim config/flink-sql/bronze_kraken_ingestion.sql

# Change INSERT statement to:
EXECUTE STATEMENT SET BEGIN
  INSERT INTO market_data.bronze_binance_trades_flink
  SELECT ... FROM default_catalog.default_database.kafka_source_binance;
END;

# Rebuild image
docker build -f Dockerfile.flink -t flink-k2:1.19.1 .

# Restart jobs
docker compose stop flink-bronze-binance-job flink-bronze-kraken-job
docker compose rm -f flink-bronze-binance-job flink-bronze-kraken-job
docker compose up -d flink-bronze-binance-job flink-bronze-kraken-job

# Verify jobs running
curl -s http://localhost:8082/jobs | jq '.jobs[] | {id, status}'
# Expected: 2 jobs with "status": "RUNNING"
```

---

## 5. Query Data (1 minute)

Once jobs are running:

```bash
# Query Iceberg table via DuckDB
docker exec -it k2-query-api duckdb -c "
INSTALL iceberg;
LOAD iceberg;

SELECT COUNT(*),
       MIN(ingestion_timestamp),
       MAX(ingestion_timestamp)
FROM iceberg_scan('s3://warehouse/market_data/bronze_binance_trades_flink');
"
```

**Expected output**: Rows with recent timestamps

‚úÖ **Checkpoint**: Data flowing to Iceberg tables

---

## Troubleshooting

### Problem: Flink Web UI not accessible

```bash
# Check JobManager logs
docker logs k2-flink-jobmanager | tail -50

# Common issues:
# - Port 8082 already in use
# - Container failed to start
# - Network issues
```

### Problem: Jobs not appearing in Web UI

**This is the current known issue.** Follow fix in Step 4 above.

### Problem: No data in Iceberg tables

```bash
# Check if Kafka topics have messages
docker exec k2-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic binance.raw \
  --max-messages 5

# Check Flink job exceptions
JOB_ID="<from Web UI>"
curl -s http://localhost:8082/jobs/$JOB_ID/exceptions | jq '.'
```

---

## Useful Links

- **Flink Web UI**: http://localhost:8082
- **TaskManagers**: http://localhost:8082/taskmanagers
- **Jobs**: http://localhost:8082/jobs
- **Metrics**: http://localhost:9091/metrics
- **Grafana**: http://localhost:3000

---

## Next Steps

1. ‚úÖ **Infrastructure**: Complete
2. üü° **Jobs**: Apply `EXECUTE STATEMENT SET` fix (5 min)
3. ‚¨ú **Validation**: Run 24-hour stability test
4. ‚¨ú **Monitoring**: Create Grafana dashboard
5. ‚¨ú **Migration**: Update Silver layer to read from Flink tables

---

## Resource Usage

```bash
# Check resource consumption
docker stats k2-flink-jobmanager k2-flink-taskmanager-1 k2-flink-taskmanager-2

# Expected:
# - JobManager: ~1 CPU, ~1GB RAM
# - TaskManager-1: ~2 CPU, ~2GB RAM
# - TaskManager-2: ~2 CPU, ~2GB RAM
# Total: ~5 CPU, ~5GB RAM (vs Spark: 13 CPU, 12GB RAM)
```

---

## Documentation

- **Full Implementation Plan**: `IMPLEMENTATION_PLAN.md`
- **Operations Runbook**: `RUNBOOK.md`
- **Implementation Status**: `IMPLEMENTATION_STATUS.md`
- **JAR Manifest**: `reference/flink-jars-manifest.md`

---

**Status**: Infrastructure 100% ready, Jobs 95% complete (1 SQL statement away from production)

**Total Setup Time**: 5 minutes (cluster) + 5 minutes (fix) = **10 minutes to production**
